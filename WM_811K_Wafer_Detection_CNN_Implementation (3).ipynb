{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import label_binarize"
      ],
      "metadata": {
        "id": "BI__h7B8iVra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHdgym-hhh0f"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"qingyi/wm811k-wafer-map\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/root/.cache/kagglehub/datasets/qingyi/wm811k-wafer-map/versions/1/LSWMD.pkl', 'rb') as f:\n",
        "    raw_data = pd.read_pickle(f)\n",
        "\n",
        "print(raw_data)"
      ],
      "metadata": {
        "id": "aHK2Ko2MlAyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oversampleData(wafers, defect_type):\n",
        "  temp_df = wafers.copy()\n",
        "  temp_df.drop(temp_df.index, inplace = True)\n",
        "  for index, rows in wafers.loc[wafers['failureType'] == defect_type].iterrows():\n",
        "    temp_wafer_ud = rows\n",
        "    temp_wafer_ud['waferMap'] = np.flip(temp_wafer_ud['waferMap'], 0)\n",
        "    temp_df.loc[len(temp_df)] = temp_wafer_ud\n",
        "\n",
        "    temp_wafer_lr = rows\n",
        "    temp_wafer_lr['waferMap'] = np.flip(temp_wafer_lr['waferMap'], 0)\n",
        "    temp_df.loc[len(temp_df)] = temp_wafer_lr\n",
        "\n",
        "    temp_wafer_90 = rows\n",
        "    temp_wafer_90['waferMap'] = np.rot90(temp_wafer_90['waferMap'], 1)\n",
        "    temp_df.loc[len(temp_df)] = temp_wafer_90\n",
        "\n",
        "    temp_wafer_180 = rows\n",
        "    temp_wafer_180['waferMap'] = np.rot90(temp_wafer_180['waferMap'], 1)\n",
        "    temp_df.loc[len(temp_df)] = temp_wafer_180\n",
        "\n",
        "    temp_wafer_270 = rows\n",
        "    temp_wafer_270['waferMap'] = np.rot90(temp_wafer_270['waferMap'], 1)\n",
        "    temp_df.loc[len(temp_df)] = temp_wafer_270\n",
        "\n",
        "  return temp_df\n",
        "  pass"
      ],
      "metadata": {
        "id": "YmfGJ96N3F3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def describeWaferData(wafer_data, classes):\n",
        "  for classType in classes:\n",
        "    count = (wafer_data['failureType'] == classType).sum()\n",
        "    print(classType + \": \" + str(count))"
      ],
      "metadata": {
        "id": "lQr9awiVu8Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printWaferMap(wafer, prediction = \"\"):\n",
        "  # Generate a plot using the binary colormap\n",
        "  # Wafer area is indicated by grey, defects are indicated in black\n",
        "  wafer_map = wafer['waferMap']\n",
        "  plt.imshow(wafer_map, cmap='binary', interpolation='nearest')\n",
        "\n",
        "  plt.suptitle(\"Labeled Defect: \" + str(wafer['failureType'][0][0]))\n",
        "\n",
        "  plt.show()\n",
        "  pass"
      ],
      "metadata": {
        "id": "_1eIIENdtqXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testModel(test_loader, defect_classes):\n",
        "  # Evaluate the model\n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(len(defect_classes))]\n",
        "    n_class_samples = [0 for i in range(len(defect_classes))]\n",
        "    for images, labels in test_loader:\n",
        "      images = images.float().to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      n_samples += labels.size(0)\n",
        "      n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "      current_batch_size = labels.size(0)\n",
        "\n",
        "      for i in range(current_batch_size):\n",
        "        label = labels[i]\n",
        "        pred = predicted[i]\n",
        "        if (label == pred):\n",
        "          n_class_correct[label] += 1\n",
        "        n_class_samples[label] += 1\n",
        "\n",
        "  acc = round(100.0 * n_correct / n_samples, 3)\n",
        "  print(\"The test accuracy of the network is: \" + str(acc))\n",
        "\n",
        "  for i in range(len(defect_classes)):\n",
        "    acc = round(100 * n_class_correct[i]/ n_class_samples[i], 3)\n",
        "    print(defect_classes[i] + \" \" + str(acc))"
      ],
      "metadata": {
        "id": "0NkQcbHwsPLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validateModel(test_loader, defect_classes):\n",
        "  # Evaluate the model\n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(len(defect_classes))]\n",
        "    n_class_samples = [0 for i in range(len(defect_classes))]\n",
        "    for images, labels in val_loader:\n",
        "      images = images.float().to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      n_samples += labels.size(0)\n",
        "      n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "      current_batch_size = labels.size(0)\n",
        "\n",
        "      for i in range(current_batch_size):\n",
        "        label = labels[i]\n",
        "        pred = predicted[i]\n",
        "        if (label == pred):\n",
        "          n_class_correct[label] += 1\n",
        "        n_class_samples[label] += 1\n",
        "\n",
        "  acc = round(100.0 * n_correct / n_samples, 3)\n",
        "  print(\"The validation accuracy of the network is: \" + str(acc))\n",
        "\n",
        "  for i in range(len(defect_classes)):\n",
        "    acc = round(100 * n_class_correct[i]/ n_class_samples[i], 3)\n",
        "    print(defect_classes[i] + \" \" + str(acc))"
      ],
      "metadata": {
        "id": "PEWxBQkt1QyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.rename(columns={'trianTestLabel': 'trainTestLabel'}, inplace=True)\n",
        "wafer_data = raw_data[raw_data['trainTestLabel'].str.len() != 0]\n",
        "\n",
        "columns_to_drop = ['dieSize','lotName','waferIndex','trainTestLabel']\n",
        "\n",
        "wafer_data = wafer_data.drop(columns = columns_to_drop)\n",
        "wafer_data.reset_index(drop = True, inplace = True)\n",
        "print(wafer_data)"
      ],
      "metadata": {
        "id": "mJ4gplD-nhKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defect_classes = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']\n",
        "num_classes = len(defect_classes)"
      ],
      "metadata": {
        "id": "KKNYYahArHH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((wafer_data.iloc[0]['waferMap']).shape)\n",
        "printWaferMap(wafer_data.iloc[20000])"
      ],
      "metadata": {
        "id": "XxT2RuHztRaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print class distribution\n",
        "describeWaferData(wafer_data, defect_classes)"
      ],
      "metadata": {
        "id": "rE9Wy9JT1iWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, i in enumerate(wafer_data[\"waferMap\"]):\n",
        "  # theoretical maximum size is 212x212, but i don't have enough system ram\n",
        "  new_size = (120, 120)\n",
        "\n",
        "  resized_array = F.interpolate(torch.tensor(i).clone().detach().unsqueeze(0).unsqueeze(0).float(), size = new_size, mode = \"nearest\")\n",
        "  resized_array = resized_array.squeeze(0).squeeze(0)\n",
        "\n",
        "  wafer_data.loc[idx, \"waferMap\"] = np.array(resized_array)\n",
        "\n",
        "  if (idx % 10000 == 0):\n",
        "    printWaferMap(wafer_data.iloc[idx])\n",
        "    print(idx)\n"
      ],
      "metadata": {
        "id": "N5HL9LxlLmMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for defect_type in defect_classes:\n",
        "  if defect_type == 'none':\n",
        "    break\n",
        "  print(defect_type)\n",
        "  augmentation = pd.DataFrame(oversampleData(wafer_data, defect_type))\n",
        "  wafer_data = pd.concat([wafer_data.reset_index(drop=True), pd.DataFrame(augmentation).reset_index(drop=True)], ignore_index=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rOwGWapOC6BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess Data Augmentation\n",
        "describeWaferData(wafer_data, defect_classes)"
      ],
      "metadata": {
        "id": "MRR5UL5KI9OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 150\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "-mH9YBCmfxph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.wafer_data = dataframe\n",
        "        self.waferMap = dataframe[\"waferMap\"]\n",
        "        self.failureType = dataframe[\"failureType\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.waferMap)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        waferMap = self.waferMap.iloc[idx]\n",
        "        failureType = self.failureType.iloc[idx]\n",
        "        failureType = np.array(failureType)\n",
        "        waferMap = np.array(waferMap)\n",
        "\n",
        "        failureType_mapping = {'Center': 0, 'Donut' : 1, 'Edge-Loc' : 2, 'Edge-Ring' : 3, 'Loc' : 4, 'Near-full' : 5, 'Random' : 6, 'Scratch' : 7, 'none' : 8}\n",
        "        failureType = failureType_mapping[failureType[0][0]]\n",
        "\n",
        "        return waferMap, failureType"
      ],
      "metadata": {
        "id": "WD-_5M5g1sg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(wafer_data))\n",
        "custom_wafer_data = CustomDataset(wafer_data)\n",
        "print(custom_wafer_data.__len__())"
      ],
      "metadata": {
        "id": "wJjZVCtF5BGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(custom_wafer_data))\n",
        "val_size = int(0.1 * len(custom_wafer_data))\n",
        "test_size = len(custom_wafer_data) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(custom_wafer_data, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "gW6JG4ZCbJci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, 5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "    self.fc1 = nn.Linear(23328, 512)\n",
        "    self.fc2 = nn.Linear(512, 128)\n",
        "    self.fc3 = nn.Linear(128, len(defect_classes))\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.unsqueeze(1)\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "    pass"
      ],
      "metadata": {
        "id": "1Of6PrS4m0sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jLZsAZegnNOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Current Epoch: \" + str(epoch + 1))\n",
        "  if((epoch + 1) % 10 == 0):\n",
        "    validateModel(val_loader, defect_classes)\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.float().to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Training Complete\")"
      ],
      "metadata": {
        "id": "MGFj4m8Wnh_f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(test_loader,defect_classes)"
      ],
      "metadata": {
        "id": "yKbRNnJ9ZI8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions and true labels for the test set\n",
        "y_true = []\n",
        "y_scores = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.float().to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "y_scores = np.array(y_scores)\n",
        "\n",
        "# Binarize the true labels for multi-class AUROC calculation\n",
        "y_true_bin = label_binarize(y_true, classes=list(range(len(defect_classes))))\n",
        "\n",
        "# Compute macro-average AUROC\n",
        "auroc_macro = roc_auc_score(y_true_bin, y_scores, average='macro', multi_class='ovr')\n",
        "print(f\"Macro-average AUROC: {auroc_macro}\")\n",
        "\n",
        "# Compute and plot ROC curves for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(len(defect_classes)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n",
        "    roc_auc[i] = roc_auc_score(y_true_bin[:, i], y_scores[:, i])\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure()\n",
        "for i in range(len(defect_classes)):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'{defect_classes[i]}')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Wafer Defect Classification')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kL6JPk_Y1kev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}